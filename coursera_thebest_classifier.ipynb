{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a coursera project for classification algorithms kNN, logistic regression, decision trees and svm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read & pre-process training data\n",
    "\n",
    "#some features are categorical we do one-hot-encoding for education and label encoding 0,1 for male&female\n",
    "\n",
    "#X_trn:features\n",
    "#Y_trn:label\n",
    "\n",
    "data_trn = pd.read_csv('loan_train.csv')\n",
    "\n",
    "#if it is weekend loan do not be paid\n",
    "data_trn['effective_date'] = pd.to_datetime(data_trn['effective_date'])\n",
    "\n",
    "data_trn['dayofweek'] = data_trn['effective_date'].dt.dayofweek\n",
    "\n",
    "data_trn['weekend'] = data_trn['dayofweek'].apply(lambda x: 1 if (x>5)  else 0)\n",
    "\n",
    "\n",
    "data_trn['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)\n",
    "data_trn.head()\n",
    "\n",
    "X_trn = data_trn[['Principal','terms','age','Gender', 'weekend']]\n",
    "X_trn = pd.concat([X_trn,pd.get_dummies(data_trn['education'])], axis=1)\n",
    "\n",
    "\n",
    "Y_trn =data_trn['loan_status']\n",
    "\n",
    "#Normalization process for the distances\n",
    "\n",
    "X_trn=preprocessing.StandardScaler().fit(X_trn).transform(X_trn.astype(float))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read& pre-process test data\n",
    "\n",
    "#some features are categorical we do one-hot-encoding for education and label encoding  0,1 for male&female\n",
    "\n",
    "#X_tst:features\n",
    "#Y_tst:label\n",
    "\n",
    "data_tst = pd.read_csv('loan_test.csv')\n",
    "\n",
    "data_tst['effective_date'] = pd.to_datetime(data_tst['effective_date'])\n",
    "\n",
    "data_tst['dayofweek'] = data_tst['effective_date'].dt.dayofweek\n",
    "\n",
    "data_tst['weekend'] = data_tst['dayofweek'].apply(lambda x: 1 if (x>5)  else 0)\n",
    "data_tst.head()\n",
    "\n",
    "\n",
    "\n",
    "data_tst['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)\n",
    "\n",
    "\n",
    "X_tst = data_tst[['Principal','terms','age','Gender', 'weekend']]\n",
    "X_tst = pd.concat([X_tst,pd.get_dummies(data_tst['education'])], axis=1)\n",
    "\n",
    "\n",
    "Y_tst = data_tst['loan_status']\n",
    "\n",
    "\n",
    "#Normalization process for the distances\n",
    "\n",
    "X_tst=preprocessing.StandardScaler().fit(X_tst).transform(X_tst.astype(float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64285714, 0.54285714, 0.75714286, 0.71428571, 0.8       ,\n",
       "       0.75714286, 0.75714286, 0.71428571, 0.72857143])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding the best k for kNN\n",
    "\n",
    "#we do not use loan_test data, instead we split training data to find the best k value\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "X, X_t, Y, Y_t = train_test_split( X_trn, Y_trn, test_size=0.2, random_state=4)\n",
    "#train, test, train, test\n",
    "K=10\n",
    "accuracy=np.zeros(K-1)\n",
    "for n in range(1, K):\n",
    "    model_kNN = KNeighborsClassifier(n_neighbors = n).fit(X,Y)\n",
    "    accuracy[n-1] = metrics.accuracy_score(Y_t, model_kNN.predict(X_t))\n",
    "    \n",
    "accuracy    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification\n",
    "\n",
    "# kNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "\n",
    "k = 5\n",
    "model_kNN = KNeighborsClassifier(n_neighbors = k).fit(X_trn,Y_trn)\n",
    "\n",
    "model_DT = DecisionTreeClassifier(criterion ='entropy', max_depth = 6).fit(X_trn, Y_trn)\n",
    "\n",
    "model_LR = LogisticRegression(C=0.1, solver='liblinear').fit(X_trn, Y_trn)\n",
    "\n",
    "model_SVM = svm.SVC(kernel = 'linear').fit(X_trn, Y_trn)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN Algorithm\n",
      "Jaccard Train set Accuracy:  0.8063583815028902\n",
      " Jaccard Test set Accuracy:  0.7222222222222222\n",
      "F1_score: paid off, collection [0.28571429 0.82758621]\n",
      "Decision Tree Algorithm\n",
      "Jaccard Train set Accuracy:  0.7832369942196532\n",
      "Jaccard Test set Accuracy:  0.7222222222222222\n",
      "F1_score: paid off, collection [0.34782609 0.82352941]\n",
      "Logistic Regression\n",
      "Jaccard Train set Accuracy:  0.7456647398843931\n",
      "Jaccard Test set Accuracy:  0.7407407407407407\n",
      "F1_score: paid off, collection [0.         0.85106383]\n",
      "SVM\n",
      "Jaccard Train set Accuracy:  0.7514450867052023\n",
      "Jaccard Test set Accuracy:  0.7407407407407407\n",
      "F1_score: paid off, collection [0.         0.85106383]\n"
     ]
    }
   ],
   "source": [
    "#Accuracy metrics\n",
    "#kNN: jaccard similarity, f1 score\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"kNN Algorithm\")\n",
    "print(\"Jaccard Train set Accuracy: \", metrics.accuracy_score(Y_trn, model_kNN.predict(X_trn)))\n",
    "print(\" Jaccard Test set Accuracy: \", metrics.accuracy_score(Y_tst,  model_kNN.predict(X_tst)))\n",
    "\n",
    "print(\"F1_score: paid off, collection\", metrics.f1_score(Y_tst, model_kNN.predict(X_tst), average = None))\n",
    "\n",
    "\n",
    "print(\"Decision Tree Algorithm\")\n",
    "print(\"Jaccard Train set Accuracy: \", metrics.accuracy_score(Y_trn, model_DT.predict(X_trn)))\n",
    "print(\"Jaccard Test set Accuracy: \", metrics.accuracy_score(Y_tst,  model_DT.predict(X_tst)))\n",
    "print(\"F1_score: paid off, collection\", metrics.f1_score(Y_tst, model_DT.predict(X_tst), average = None))\n",
    "\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(\"Jaccard Train set Accuracy: \", metrics.accuracy_score(Y_trn, model_LR.predict(X_trn)))\n",
    "print(\"Jaccard Test set Accuracy: \", metrics.accuracy_score(Y_tst,  model_LR.predict(X_tst)))\n",
    "print(\"F1_score: paid off, collection\", metrics.f1_score(Y_tst, model_LR.predict(X_tst), average = None))\n",
    "#print(\"Logloss:\", metrics.log_loss(Y_tst, model_LR.predict(X_tst)))\n",
    "\n",
    "print(\"SVM\")\n",
    "print(\"Jaccard Train set Accuracy: \", metrics.accuracy_score(Y_trn, model_SVM.predict(X_trn)))\n",
    "print(\"Jaccard Test set Accuracy: \", metrics.accuracy_score(Y_tst,  model_SVM.predict(X_tst)))\n",
    "print(\"F1_score: paid off, collection\", metrics.f1_score(Y_tst, model_SVM.predict(X_tst), average = None))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
